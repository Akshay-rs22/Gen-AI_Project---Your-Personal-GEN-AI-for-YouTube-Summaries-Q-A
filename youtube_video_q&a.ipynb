{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "828fe108"
      },
      "source": [
        "## EchoTube: Your Personal GEN-AI for YouTube Summaries & Q&A"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wI8hEVDe35F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "custom_package_path = '/content/drive/MyDrive/my_colab_packages'\n",
        "\n",
        "if custom_package_path not in sys.path:\n",
        "    sys.path.insert(0, custom_package_path)\n",
        "\n",
        "print(f\"Custom package path added to sys.path: {custom_package_path}\")\n",
        "print(f\"Current sys.path: {sys.path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6IHpSznwwAV",
        "outputId": "381ce54c-0b45-4555-efce-3701a1f70e13"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom package path added to sys.path: /content/drive/MyDrive/my_colab_packages\n",
            "Current sys.path: ['/content/drive/MyDrive/my_colab_packages', '/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmpmmdfeje6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q youtube-transcript-api langchain-community langchain-text-splitters faiss-cpu tiktoken python-dotenv pytube\n",
        "\n",
        "import os\n",
        "import re\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound, RequestBlocked\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from google.colab import drive\n",
        "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline"
      ],
      "metadata": {
        "id": "bL-znby0FSWN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "156179e3",
        "outputId": "7b7a53b7-aa50-4266-e69c-7304d445d4a8"
      },
      "source": [
        "\n",
        "\n",
        "# Define the path where models are stored\n",
        "model_storage_path = '/content/drive/MyDrive/colab_models'\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def get_youtube_video_id(url):\n",
        "    \"\"\"\n",
        "    Extracts the YouTube video ID from a given YouTube URL.\n",
        "    \"\"\"\n",
        "    if \"youtube.com/watch?v=\" in url:\n",
        "        match = re.search(r\"v=([\\w-]+)\", url)\n",
        "    elif \"youtu.be/\" in url:\n",
        "        match = re.search(r\"youtu.be/([\\w-]+)\", url)\n",
        "    elif \"youtube.com/embed/\" in url:\n",
        "        match = re.search(r\"embed/([\\w-]+)\", url)\n",
        "    elif \"youtube.com/v/\" in url:\n",
        "        match = re.search(r\"v/([\\w-]+)\", url)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "    if match:\n",
        "        return match.group(1)\n",
        "    return None\n",
        "\n",
        "def load_embedding_model_interactive():\n",
        "    embedding_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "    local_embedding_model_dir = os.path.join(model_storage_path, embedding_model_id.split('/')[-1])\n",
        "\n",
        "    if not os.path.exists(local_embedding_model_dir):\n",
        "        print(f\"Error: Embedding model not found at {local_embedding_model_dir}. Please ensure it's downloaded and available.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Loading embedding model: {embedding_model_id}...\")\n",
        "    embedding_model = HuggingFaceEmbeddings(\n",
        "        model_name=local_embedding_model_dir,\n",
        "        model_kwargs={'device': 'cpu'},\n",
        "        encode_kwargs={'normalize_embeddings': False}\n",
        "    )\n",
        "    print(\"Embedding model loaded!\")\n",
        "    return embedding_model\n",
        "\n",
        "def load_llm_model_interactive():\n",
        "    llm_model_id = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n",
        "    local_llm_model_dir = os.path.join(model_storage_path, llm_model_id.split('/')[-1])\n",
        "\n",
        "    if not os.path.exists(local_llm_model_dir):\n",
        "        print(f\"Error: LLM model not found at {local_llm_model_dir}. Please ensure it's downloaded and available.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Loading LLM model: {llm_model_id}...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(local_llm_model_dir)\n",
        "    model = AutoModelForCausalLM.from_pretrained(local_llm_model_dir)\n",
        "    # pipe = pipeline(\n",
        "    #     \"text-generation\",\n",
        "    #     model=model,\n",
        "    #     tokenizer=tokenizer,\n",
        "    #     max_new_tokens=150,\n",
        "    #     temperature=0.7,\n",
        "    #     top_p=0.9,\n",
        "    #     pad_token_id=tokenizer.eos_token_id\n",
        "    # )\n",
        "    # llm = HuggingFacePipeline(pipeline=pipe)\n",
        "    # Create a Hugging Face pipeline\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        temperature=0.5,\n",
        "        max_new_tokens=500, # Set a reasonable limit for generated text\n",
        "        # Other pipeline arguments can be added here as needed\n",
        "    )\n",
        "\n",
        "    # Wrap the pipeline with HuggingFacePipeline for LangChain compatibility\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "    model = ChatHuggingFace(llm=llm)\n",
        "\n",
        "\n",
        "    #print(\"LLM model loaded!\")\n",
        "    return model\n",
        "\n",
        "# --- Load models once at the beginning ---\n",
        "print(\"\\n--- Initializing Models ---\")\n",
        "embedding_model = load_embedding_model_interactive()\n",
        "llm = load_llm_model_interactive()\n",
        "\n",
        "if embedding_model is None or llm is None:\n",
        "    print(\"Exiting due to model loading errors. Please ensure models are correctly downloaded.\")\n",
        "else:\n",
        "    print(\"\\n--- YouTube Video Q&A ---\")\n",
        "    youtube_url = input(\"Enter YouTube Video URL (or 'exit' to quit): \")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #user_question = input(\"Ask a question about the video: \")\n",
        "\n",
        "    if not youtube_url:\n",
        "        print(\"Error: Please enter a YouTube video URL.\")\n",
        "\n",
        "    else:\n",
        "        print(\"\\nProcessing video and generating answer...\")\n",
        "        video_id = get_youtube_video_id(youtube_url)\n",
        "\n",
        "        if not video_id:\n",
        "            print(\"Error: Could not extract video ID from the provided URL. Please check the URL.\")\n",
        "        else:\n",
        "            transcript_text = \"\"\n",
        "            try:\n",
        "                # Clear any existing proxy environment variables to avoid conflicts\n",
        "                if 'http_proxy' in os.environ: del os.environ['http_proxy']\n",
        "                if 'https_proxy' in os.environ: del os.environ['https_proxy']\n",
        "\n",
        "                ytt_api = YouTubeTranscriptApi()\n",
        "                transcript_text = \" \".join([snippet.text for snippet in ytt_api.fetch(video_id)])\n",
        "                if not transcript_text:\n",
        "                    print(\"Warning: Transcript fetched but it's empty. Cannot answer questions.\")\n",
        "            except TranscriptsDisabled:\n",
        "                print(\"Error: Transcripts are disabled for this video.\")\n",
        "            except NoTranscriptFound:\n",
        "                print(\"Error: No transcript found for this video in available languages.\")\n",
        "            except RequestBlocked:\n",
        "                print(\"Error: YouTube blocked the transcript request. This often happens from cloud servers. Consider using a proxy if this persists.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error: An unexpected error occurred while fetching transcript: {e}\")\n",
        "\n",
        "            if transcript_text:\n",
        "                # --- Indexing (Chunking and Vector Store) ---\n",
        "                splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "                chunks = splitter.create_documents([transcript_text])\n",
        "\n",
        "                vector_store = FAISS.from_documents(chunks, embedding_model)\n",
        "\n",
        "                # --- Retrieval ---\n",
        "                retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})\n",
        "\n",
        "\n",
        "                # --- Augmentation ---\n",
        "                # context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "                # prompt = PromptTemplate(\n",
        "                #     template=\"\"\"\n",
        "                #       You are a helpful assistant.\n",
        "                #       Answer ONLY from the provided transcript context. If the context is insufficient, state that you don't have enough information.\n",
        "\n",
        "                #       Context: {context}\n",
        "                #       Question: {question}\n",
        "                #     \"\"\",\n",
        "                #     input_variables=['context', 'question']\n",
        "                # )\n",
        "                # while True:\n",
        "                #   user_question = input(\"Ask a question about the video: \")\n",
        "                #   if not user_question:\n",
        "                #     print(\"Error: Please enter a question.\")\n",
        "                #   if user_question.lower() == 'exit':\n",
        "                #     print(\"Exiting Q&A session.\")\n",
        "                #     break\n",
        "                #   final_prompt_value = prompt.invoke({\"context\": context_text, \"question\": user_question})\n",
        "                #   final_prompt = final_prompt_value.text\n",
        "\n",
        "                #   # --- Generation ---\n",
        "                #   try:\n",
        "                #       answer = llm.invoke(final_prompt)\n",
        "\n",
        "                #       # Clean up potentially repeated prompt from TinyLlama output\n",
        "                #       cleaned_answer = answer.content.split('Question: ' + user_question)[-1].strip()\n",
        "                #       cleaned_answer = cleaned_answer.replace('\\n', ' ')\n",
        "                #       # ANSI escape code for white text: \\033[97m, and reset: \\033[0m\n",
        "                #       print(f\"\\n--- Answer ---\\n\\033[97m{cleaned_answer}\\033[0m\")\n",
        "                #   except Exception as e:\n",
        "                #       print(f\"Error generating answer from LLM: {e}\")\n",
        "                #   else:\n",
        "                #     print(\"Cannot answer questions without a transcript.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initializing Models ---\n",
            "Loading embedding model: sentence-transformers/all-MiniLM-L6-v2...\n",
            "Embedding model loaded!\n",
            "Loading LLM model: TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- YouTube Video Q&A ---\n",
            "Enter YouTube Video URL (or 'exit' to quit): https://youtu.be/WSDcYUrGODE?si=ducQBdEgt0HwJK4G\n",
            "\n",
            "Processing video and generating answer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcript_text = \" \".join([snippet.text for snippet in ytt_api.fetch(video_id)])\n",
        "print(transcript_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAHCbYwOSAqQ",
        "outputId": "fcb59437-ebe0-400d-b9ee-3db883c7cb84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are Newton's three laws of motion? Sir Isaac Newton was a famous scientist that lived almost 400 years ago. He is famous for learning and understanding how and why objects move. Like when an apple falls from a tree. Because he figured out why objects move. We call them Newton's three laws of motion. The first is called the Law of inertia and explains why things move. It says that an object at rest stays at rest, and an object in motion stays in motion at its same speed and direction, unless acted upon by another force. So this ball just sitting in the grass won't start moving on its own. It'll just sit there at rest. But if I kick it, my foot would be applying a force to it. And the ball would move. Newton's second law talks about how objects change when a force acts on it. This law says the acceleration of an object is directly proportional to the net force acting on it, and inversely proportional to its mass. Sounds pretty confusing, doesn't it? Indeed. Which brings us to Newton's third law of motion. For every action, there is an equal and opposite reaction. Think of a swimmer moving through the water to go. The swimmer pushes the water backward with their hands. That's the action. The water pushes them forward. That's the reaction. Or think of a rocket ship. It shoots out gases down. That's the action. And the gases push the rocket up. That's the reaction. The action and reaction is the force, and they are always equal in strength. But go in exactly the opposite direction. And those are Sir Isaac Newton's three laws of motion. Number one, things\n",
            "stay still or keep moving unless a force changes them. Number two, the amount of force, mass, and acceleration are all connected. The math formula is f equals m times a. And remember every action has an equal and opposite reaction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "\n",
        "  user_question = input(\"\\n Ask a question about the video: \")\n",
        "  if not user_question:\n",
        "    print(\"Error: Please enter a question.\")\n",
        "  if user_question.lower() == 'exit':\n",
        "    print(\"Exiting Q&A session.\")\n",
        "    break\n",
        "  retrieved_docs = retriever.invoke(user_question)\n",
        "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "  prompt = PromptTemplate(\n",
        "                    template=\"\"\"\n",
        "                      You are a helpful assistant.\n",
        "                      Answer ONLY from the provided transcript context. If the context is insufficient, state that you don't have enough information.\n",
        "\n",
        "                      Context: {context}\n",
        "                      Question: {question}\n",
        "                    \"\"\",\n",
        "                    input_variables=['context', 'question']\n",
        "                    )\n",
        "  final_prompt_value = prompt.invoke({\"context\": context_text, \"question\": user_question})\n",
        "  final_prompt = final_prompt_value.text\n",
        "\n",
        "  # --- Generation ---\n",
        "  try:\n",
        "      answer = llm.invoke(final_prompt)\n",
        "\n",
        "      # Clean up potentially repeated prompt from TinyLlama output\n",
        "      cleaned_answer = answer.content.split('Question: ' + user_question)[-1].strip()\n",
        "      cleaned_answer = cleaned_answer.replace('\\n', ' ')\n",
        "      # ANSI escape code for white text: \\033[97m, and reset: \\033[0m\n",
        "      print(f\"--- Answer ---:{cleaned_answer}\")\n",
        "  except Exception as e:\n",
        "      print(f\"Error generating answer from LLM: {e}\")\n",
        "  else:\n",
        "    print(\"Cannot answer questions without a transcript.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0dAAv-XPpd4",
        "outputId": "04124084-27a7-4be2-d583-5ba33d0f11e6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Ask a question about the video: what is newton first law?\n",
            "--- Answer ---:</s> <|assistant|> Newton's first law of motion is called the Law of Inertia and explains why objects move in a straight line unless a force is applied to them. The first law states that an object at rest remains at rest, and an object in motion stays in motion at the same speed and direction unless acted upon by a force.\n",
            "Cannot answer questions without a transcript.\n",
            "\n",
            " Ask a question about the video: explain me newton second law\n",
            "--- Answer ---:</s> <|assistant|> The second law of motion, as explained by Sir Isaac Newton, is a fundamental principle of physics that states that the acceleration of an object is directly proportional to the net force acting on it and inversely proportional to its mass. This law is also known as the law of universal gravitation and explains why objects move in a predictable and consistent way. The action and reaction of a force are always equal in strength, but the direction of the force is opposite to the direction of the reaction. For example, when an object is pushed by a force in the opposite direction, it moves in the opposite direction. This principle is essential in understanding other laws of motion, such as the law of inertia, which explains why objects stay at rest or move at their same speed and direction unless acted upon by another force.\n",
            "Cannot answer questions without a transcript.\n",
            "\n",
            " Ask a question about the video: what is formula of force?\n",
            "--- Answer ---:</s> <|assistant|> The formula for force is F = m * a, where F is the force, m is the mass, and a is the acceleration. This formula is derived from the principle of inertia and the law of conservation of momentum. The first law of motion states that an object at rest stays at rest or has a constant velocity, and an object in motion has a constant acceleration. The second law of motion states that the net force acting on an object is equal to its mass multiplied by its acceleration, and the formula for force is derived from this law.\n",
            "Cannot answer questions without a transcript.\n",
            "\n",
            " Ask a question about the video: exit\n",
            "Exiting Q&A session.\n"
          ]
        }
      ]
    }
  ]
}